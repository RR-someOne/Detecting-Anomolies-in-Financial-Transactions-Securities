{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 7213,
          "sourceType": "datasetVersion",
          "datasetId": 4538
        }
      ],
      "dockerImageVersionId": 31234,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Anomoly Detection - Finance Data",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RR-someOne/Detecting-Anomolies-in-Financial-Transactions-Securities/blob/main/Anomoly_Detection_Finance_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "borismarjanovic_price_volume_data_for_all_us_stocks_etfs_path = kagglehub.dataset_download('borismarjanovic/price-volume-data-for-all-us-stocks-etfs')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "e3fKQBOu7GzV"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Anomaly Detection in Finance\n",
        "\n",
        "Anomaly detection is a critical analytical approach in finance that focuses on identifying unusual, rare, or suspicious patterns in financial data that deviate from normal behavior. These anomalies often act as early warning signals for risk, fraud, or abnormal market activity, enabling financial institutions to take timely corrective or preventive actions.\n",
        "\n",
        "Modern financial systems generate massive volumes of data, including transaction records, market prices, order flows, and customer activity logs. Manual monitoring of such data is impractical, making machine learning–based anomaly detection an essential tool for automated surveillance and risk management. By learning patterns of normal behavior, anomaly detection models can efficiently surface irregularities that require further investigation.\n",
        "\n",
        "## Key Use Cases\n",
        "## Fraud Detection\n",
        "\n",
        "Identify abnormal transactions such as:\n",
        "\n",
        "Unauthorized payments\n",
        "\n",
        "Identity theft\n",
        "\n",
        "Unusual spending patterns\n",
        "\n",
        "## Market Manipulation Detection\n",
        "\n",
        "Detect suspicious trading behaviors including:\n",
        "\n",
        "Spoofing\n",
        "\n",
        "Pump-and-dump schemes\n",
        "\n",
        "Insider trading signals\n",
        "\n",
        "Abnormal price or volume movements\n",
        "\n",
        "## Risk Monitoring\n",
        "\n",
        "Monitor and flag:\n",
        "\n",
        "Extreme portfolio losses\n",
        "\n",
        "Liquidity stress events\n",
        "\n",
        "System or trading failures\n",
        "\n",
        "Unusual counterparty behavior\n",
        "\n",
        "## Common Algorithms Used\n",
        "\n",
        "Isolation Forest – Efficient for large-scale, high-dimensional financial data\n",
        "\n",
        "One-Class SVM – Learns normal behavior and detects deviations\n",
        "\n",
        "Autoencoders – Neural networks that identify anomalies via reconstruction error\n",
        "\n",
        "Local Outlier Factor (LOF) – Detects anomalies based on local data density\n",
        "\n",
        "## Why Anomaly Detection Matters in Finance\n",
        "\n",
        "Most financial anomalies are rare and unlabeled\n",
        "\n",
        "Early detection helps reduce financial losses and regulatory risk\n",
        "\n",
        "Suitable for real-time monitoring and surveillance systems\n",
        "\n",
        "## Key Challenges\n",
        "\n",
        "Highly imbalanced datasets\n",
        "\n",
        "Concept drift, where normal behavior evolves over time\n",
        "\n",
        "Requirement for low false-positive rates in regulated environments"
      ],
      "metadata": {
        "id": "EvNc5WJ67GzW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Data\n",
        "\n",
        "This Python 3 environment comes with many helpful analytics libraries installed\n",
        "It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "For example, here's several helpful packages to load\n"
      ],
      "metadata": {
        "id": "mp6tbUtJ7GzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%capture captured\n",
        "print(\"Hidden output\")\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-04T16:44:23.457691Z",
          "iopub.execute_input": "2026-01-04T16:44:23.45832Z",
          "iopub.status.idle": "2026-01-04T16:44:36.512476Z",
          "shell.execute_reply.started": "2026-01-04T16:44:23.458288Z",
          "shell.execute_reply": "2026-01-04T16:44:36.51141Z"
        },
        "id": "tL1Ki2t67GzX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Identifying Market Manipulation Patterns\n",
        "### Spoofing\n",
        "\n",
        "Definition:\n",
        "Placing large buy/sell orders with no intention of executing them, to create a false impression of supply or demand and manipulate prices.\n",
        "\n",
        "Indicators:\n",
        "\n",
        "High cancellation rate: Orders are placed and canceled frequently before execution.\n",
        "\n",
        "Order imbalance: A sudden skew in buy vs sell orders that doesn’t reflect actual trading interest.\n",
        "\n",
        "Example:\n",
        "A trader places a large sell order to push the price down, then buys at the lower price and cancels the large sell order."
      ],
      "metadata": {
        "id": "2irtffjq7GzX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ML Workflow: Market Manipulation Detection Using Isolation Forest\n",
        "\n",
        "## Problem Definition\n",
        "\n",
        "Goal: Detect suspicious trading patterns (e.g., spoofing) in ETFs and stocks using historical transaction data.\n",
        "\n",
        "### Indicators to consider:\n",
        "\n",
        "High cancellation rate\n",
        "\n",
        "Order imbalance (buy vs sell orders)\n",
        "\n",
        "Abnormal volume spikes\n",
        "\n",
        "Extreme price movements\n",
        "\n",
        "Type of ML: Unsupervised anomaly detection\n",
        "\n",
        "Algorithm: Isolation Forest"
      ],
      "metadata": {
        "id": "UpCsQTx47GzX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Collection\n",
        "\n",
        "Source: .txt files with trade/order data. Check the format of the financial data and features (ETFs/Stocks)\n",
        "\n"
      ],
      "metadata": {
        "id": "kW3fsHqR7GzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "PRICE_VOLUME_DATA_FOR_ALL_US_STOCKS_ETFS_PATH = '/kaggle/input/price-volume-data-for-all-us-stocks-etfs/ETFs'\n",
        "\n",
        "def get_sample_text_files_ETFs(directory_path, sample_size=5):\n",
        "    \"\"\"\n",
        "    Walks through a directory, finds all .txt files, and returns a random sample.\n",
        "\n",
        "    Args:\n",
        "        directory_path (str): The path to the directory to search.\n",
        "        sample_size (int): The number of sample text files to return.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of paths to sample text files.\n",
        "    \"\"\"\n",
        "    text_files = []\n",
        "    for dirpath, _, filenames in os.walk(directory_path):\n",
        "        for filename in filenames:\n",
        "            if filename.endswith('.txt'):\n",
        "                text_files.append(os.path.join(dirpath, filename))\n",
        "                #print(text_files)\n",
        "\n",
        "    if len(text_files) <= sample_size:\n",
        "        return text_files\n",
        "    else:\n",
        "        return random.sample(text_files, sample_size)\n",
        "\n",
        "# Get a sample of text files from the downloaded Kaggle dataset path\n",
        "sample_files = get_sample_text_files_ETFs(PRICE_VOLUME_DATA_FOR_ALL_US_STOCKS_ETFS_PATH, sample_size=10)\n",
        "\n",
        "print(\"Sample of text files from the dataset directory:\")\n",
        "for f in sample_files:\n",
        "    print(f)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-04T16:44:36.514052Z",
          "iopub.execute_input": "2026-01-04T16:44:36.514377Z",
          "iopub.status.idle": "2026-01-04T16:44:36.530607Z",
          "shell.execute_reply.started": "2026-01-04T16:44:36.514351Z",
          "shell.execute_reply": "2026-01-04T16:44:36.529745Z"
        },
        "id": "vHj82gMx7GzX",
        "outputId": "affeec06-826e-43fc-9064-133238e19f7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Sample of text files from the dataset directory:\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/ETFs/psk.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/ETFs/ryf.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/ETFs/hap.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/ETFs/dfj.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/ETFs/unl.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/ETFs/vlue.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/ETFs/lemb.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/ETFs/inp.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/ETFs/pgj.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/ETFs/eqlt.us.txt\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "PRICE_VOLUME_DATA_FOR_ALL_US_STOCKS_ETFS_PATH_STOCKS = '/kaggle/input/price-volume-data-for-all-us-stocks-etfs/Stocks'\n",
        "\n",
        "def get_sample_text_files_Stocks(directory_path, sample_size=5):\n",
        "    \"\"\"\n",
        "    Walks through a directory, finds all .txt files, and returns a random sample.\n",
        "\n",
        "    Args:\n",
        "        directory_path (str): The path to the directory to search.\n",
        "        sample_size (int): The number of sample text files to return.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of paths to sample text files.\n",
        "    \"\"\"\n",
        "    text_files = []\n",
        "    for dirpath, _, filenames in os.walk(directory_path):\n",
        "        for filename in filenames:\n",
        "            if filename.endswith('.txt'):\n",
        "                text_files.append(os.path.join(dirpath, filename))\n",
        "                #print(text_files)\n",
        "\n",
        "    if len(text_files) <= sample_size:\n",
        "        return text_files\n",
        "    else:\n",
        "        return random.sample(text_files, sample_size)\n",
        "\n",
        "# Get a sample of text files from the downloaded Kaggle dataset path\n",
        "sample_files = get_sample_text_files_Stocks(PRICE_VOLUME_DATA_FOR_ALL_US_STOCKS_ETFS_PATH_STOCKS, sample_size=10)\n",
        "\n",
        "print(\"Sample of text files from the dataset directory:\")\n",
        "for f in sample_files:\n",
        "    print(f)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-04T16:44:48.450767Z",
          "iopub.execute_input": "2026-01-04T16:44:48.451369Z",
          "iopub.status.idle": "2026-01-04T16:44:53.745632Z",
          "shell.execute_reply.started": "2026-01-04T16:44:48.451338Z",
          "shell.execute_reply": "2026-01-04T16:44:53.744741Z"
        },
        "id": "K7tlJJRG7GzY",
        "outputId": "94006045-505f-4443-89de-3762fcba342d"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Sample of text files from the dataset directory:\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/Stocks/rlgt.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/Stocks/cht.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/Stocks/klic.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/Stocks/sni.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/Stocks/fcfs.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/Stocks/slgn.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/Stocks/cowz.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/Stocks/muj.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/Stocks/agfsw.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/Stocks/csii.us.txt\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "print(\"------------- ETF's Data Format -------------------\")\n",
        "\n",
        "file_path = '/kaggle/input/price-volume-data-for-all-us-stocks-etfs/ETFs/slyv.us.txt'\n",
        "\n",
        "try:\n",
        "    slyv_df = pd.read_csv(file_path, sep='\\t')\n",
        "    print(f\"Data from {file_path} loaded successfully. Displaying first 5 rows:\")\n",
        "    display(slyv_df.head())\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file {file_path} was not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the file: {e}\")\n",
        "\n",
        "print(\"------------- Stocks Data Format -------------------\")\n",
        "\n",
        "file_path = '/kaggle/input/price-volume-data-for-all-us-stocks-etfs/Stocks/usrt.us.txt'\n",
        "\n",
        "try:\n",
        "    slyv_df = pd.read_csv(file_path, sep='\\t')\n",
        "    print(f\"Data from {file_path} loaded successfully. Displaying first 5 rows:\")\n",
        "    display(slyv_df.head())\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file {file_path} was not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the file: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-04T16:44:53.747321Z",
          "iopub.execute_input": "2026-01-04T16:44:53.747734Z",
          "iopub.status.idle": "2026-01-04T16:44:53.777514Z",
          "shell.execute_reply.started": "2026-01-04T16:44:53.747707Z",
          "shell.execute_reply": "2026-01-04T16:44:53.776594Z"
        },
        "id": "NyQ6gMlk7GzY",
        "outputId": "0398f922-9ab5-47e1-a262-67b78f2b30c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "------------- ETF's Data Format -------------------\nData from /kaggle/input/price-volume-data-for-all-us-stocks-etfs/ETFs/slyv.us.txt loaded successfully. Displaying first 5 rows:\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "          Date,Open,High,Low,Close,Volume,OpenInt\n0   2005-02-25,44.396,44.875,44.396,44.875,2993,0\n1  2005-02-28,45.051,45.124,44.819,44.851,49043,0\n2   2005-03-01,45.051,45.293,44.972,45.293,2247,0\n3    2005-03-02,45.348,45.348,45.348,45.348,371,0\n4  2005-03-03,45.285,45.314,45.043,45.314,13855,0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date,Open,High,Low,Close,Volume,OpenInt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2005-02-25,44.396,44.875,44.396,44.875,2993,0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2005-02-28,45.051,45.124,44.819,44.851,49043,0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2005-03-01,45.051,45.293,44.972,45.293,2247,0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2005-03-02,45.348,45.348,45.348,45.348,371,0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2005-03-03,45.285,45.314,45.043,45.314,13855,0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "------------- Stocks Data Format -------------------\nData from /kaggle/input/price-volume-data-for-all-us-stocks-etfs/Stocks/usrt.us.txt loaded successfully. Displaying first 5 rows:\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "         Date,Open,High,Low,Close,Volume,OpenInt\n0  2007-05-04,38.705,38.757,38.481,38.496,5289,0\n1  2007-05-07,38.566,38.566,38.532,38.532,4257,0\n2  2007-05-08,38.424,38.424,38.278,38.295,6454,0\n3  2007-05-09,38.748,38.748,38.613,38.613,5161,0\n4     2007-05-10,38.566,38.633,38.2,38.2,12897,0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date,Open,High,Low,Close,Volume,OpenInt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2007-05-04,38.705,38.757,38.481,38.496,5289,0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2007-05-07,38.566,38.566,38.532,38.532,4257,0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2007-05-08,38.424,38.424,38.278,38.295,6454,0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2007-05-09,38.748,38.748,38.613,38.613,5161,0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2007-05-10,38.566,38.633,38.2,38.2,12897,0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--------- Features List -----------\")\n",
        "print(\"Features List: Date, Open, High, Low, Close, Volume, OpenInt\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-04T16:44:53.778605Z",
          "iopub.execute_input": "2026-01-04T16:44:53.778918Z",
          "iopub.status.idle": "2026-01-04T16:44:53.784567Z",
          "shell.execute_reply.started": "2026-01-04T16:44:53.778884Z",
          "shell.execute_reply": "2026-01-04T16:44:53.783624Z"
        },
        "id": "_2UkbFCA7GzY",
        "outputId": "00b088b2-f251-47bd-ff19-eb37d3f6df23"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "--------- Features List -----------\nFeatures List: Date, Open, High, Low, Close, Volume, OpenInt\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "kXKqpIwB7GzY"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}