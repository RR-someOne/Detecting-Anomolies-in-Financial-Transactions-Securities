{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7213,"sourceType":"datasetVersion","datasetId":4538}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Anomaly Detection in Finance\n\nAnomaly detection is a critical analytical approach in finance that focuses on identifying unusual, rare, or suspicious patterns in financial data that deviate from normal behavior. These anomalies often act as early warning signals for risk, fraud, or abnormal market activity, enabling financial institutions to take timely corrective or preventive actions.\n\nModern financial systems generate massive volumes of data, including transaction records, market prices, order flows, and customer activity logs. Manual monitoring of such data is impractical, making machine learning–based anomaly detection an essential tool for automated surveillance and risk management. By learning patterns of normal behavior, anomaly detection models can efficiently surface irregularities that require further investigation.\n\n## Key Use Cases\n## Fraud Detection\n\nIdentify abnormal transactions such as:\n\nUnauthorized payments\n\nIdentity theft\n\nUnusual spending patterns\n\n## Market Manipulation Detection\n\nDetect suspicious trading behaviors including:\n\nSpoofing\n\nPump-and-dump schemes\n\nInsider trading signals\n\nAbnormal price or volume movements\n\n## Risk Monitoring\n\nMonitor and flag:\n\nExtreme portfolio losses\n\nLiquidity stress events\n\nSystem or trading failures\n\nUnusual counterparty behavior\n\n## Common Algorithms Used\n\nIsolation Forest – Efficient for large-scale, high-dimensional financial data\n\nOne-Class SVM – Learns normal behavior and detects deviations\n\nAutoencoders – Neural networks that identify anomalies via reconstruction error\n\nLocal Outlier Factor (LOF) – Detects anomalies based on local data density\n\n## Why Anomaly Detection Matters in Finance\n\nMost financial anomalies are rare and unlabeled\n\nEarly detection helps reduce financial losses and regulatory risk\n\nSuitable for real-time monitoring and surveillance systems\n\n## Key Challenges\n\nHighly imbalanced datasets\n\nConcept drift, where normal behavior evolves over time\n\nRequirement for low false-positive rates in regulated environments","metadata":{}},{"cell_type":"markdown","source":"## Import Data\n\nThis Python 3 environment comes with many helpful analytics libraries installed\nIt is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\nFor example, here's several helpful packages to load\n","metadata":{}},{"cell_type":"code","source":"\n%%capture captured\nprint(\"Hidden output\")\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-04T16:44:23.457691Z","iopub.execute_input":"2026-01-04T16:44:23.458320Z","iopub.status.idle":"2026-01-04T16:44:36.512476Z","shell.execute_reply.started":"2026-01-04T16:44:23.458288Z","shell.execute_reply":"2026-01-04T16:44:36.511410Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## Identifying Market Manipulation Patterns\n### Spoofing\n\nDefinition:\nPlacing large buy/sell orders with no intention of executing them, to create a false impression of supply or demand and manipulate prices.\n\nIndicators:\n\nHigh cancellation rate: Orders are placed and canceled frequently before execution.\n\nOrder imbalance: A sudden skew in buy vs sell orders that doesn’t reflect actual trading interest.\n\nExample:\nA trader places a large sell order to push the price down, then buys at the lower price and cancels the large sell order.","metadata":{}},{"cell_type":"markdown","source":"## ML Workflow: Market Manipulation Detection Using Isolation Forest\n\n## Problem Definition\n\nGoal: Detect suspicious trading patterns (e.g., spoofing) in ETFs and stocks using historical transaction data.\n\n### Indicators to consider:\n\nHigh cancellation rate\n\nOrder imbalance (buy vs sell orders)\n\nAbnormal volume spikes\n\nExtreme price movements\n\nType of ML: Unsupervised anomaly detection\n\nAlgorithm: Isolation Forest","metadata":{}},{"cell_type":"markdown","source":"## Data Collection\n\nSource: .txt files with trade/order data. Check the format of the financial data and features (ETFs/Stocks)\n\n","metadata":{}},{"cell_type":"code","source":"import os\nimport random\n\nPRICE_VOLUME_DATA_FOR_ALL_US_STOCKS_ETFS_PATH = '/kaggle/input/price-volume-data-for-all-us-stocks-etfs/ETFs'\n\ndef get_sample_text_files_ETFs(directory_path, sample_size=5):\n    \"\"\"\n    Walks through a directory, finds all .txt files, and returns a random sample.\n\n    Args:\n        directory_path (str): The path to the directory to search.\n        sample_size (int): The number of sample text files to return.\n\n    Returns:\n        list: A list of paths to sample text files.\n    \"\"\"\n    text_files = []\n    for dirpath, _, filenames in os.walk(directory_path):\n        for filename in filenames:\n            if filename.endswith('.txt'):\n                text_files.append(os.path.join(dirpath, filename))\n                #print(text_files)\n    \n    if len(text_files) <= sample_size:\n        return text_files\n    else:\n        return random.sample(text_files, sample_size)\n\n# Get a sample of text files from the downloaded Kaggle dataset path\nsample_files = get_sample_text_files_ETFs(PRICE_VOLUME_DATA_FOR_ALL_US_STOCKS_ETFS_PATH, sample_size=10)\n\nprint(\"Sample of text files from the dataset directory:\")\nfor f in sample_files:\n    print(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T16:44:36.514052Z","iopub.execute_input":"2026-01-04T16:44:36.514377Z","iopub.status.idle":"2026-01-04T16:44:36.530607Z","shell.execute_reply.started":"2026-01-04T16:44:36.514351Z","shell.execute_reply":"2026-01-04T16:44:36.529745Z"}},"outputs":[{"name":"stdout","text":"Sample of text files from the dataset directory:\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/ETFs/psk.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/ETFs/ryf.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/ETFs/hap.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/ETFs/dfj.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/ETFs/unl.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/ETFs/vlue.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/ETFs/lemb.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/ETFs/inp.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/ETFs/pgj.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/ETFs/eqlt.us.txt\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import os\nimport random\n\nPRICE_VOLUME_DATA_FOR_ALL_US_STOCKS_ETFS_PATH_STOCKS = '/kaggle/input/price-volume-data-for-all-us-stocks-etfs/Stocks'\n\ndef get_sample_text_files_Stocks(directory_path, sample_size=5):\n    \"\"\"\n    Walks through a directory, finds all .txt files, and returns a random sample.\n\n    Args:\n        directory_path (str): The path to the directory to search.\n        sample_size (int): The number of sample text files to return.\n\n    Returns:\n        list: A list of paths to sample text files.\n    \"\"\"\n    text_files = []\n    for dirpath, _, filenames in os.walk(directory_path):\n        for filename in filenames:\n            if filename.endswith('.txt'):\n                text_files.append(os.path.join(dirpath, filename))\n                #print(text_files)\n    \n    if len(text_files) <= sample_size:\n        return text_files\n    else:\n        return random.sample(text_files, sample_size)\n\n# Get a sample of text files from the downloaded Kaggle dataset path\nsample_files = get_sample_text_files_Stocks(PRICE_VOLUME_DATA_FOR_ALL_US_STOCKS_ETFS_PATH_STOCKS, sample_size=10)\n\nprint(\"Sample of text files from the dataset directory:\")\nfor f in sample_files:\n    print(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T16:44:48.450767Z","iopub.execute_input":"2026-01-04T16:44:48.451369Z","iopub.status.idle":"2026-01-04T16:44:53.745632Z","shell.execute_reply.started":"2026-01-04T16:44:48.451338Z","shell.execute_reply":"2026-01-04T16:44:53.744741Z"}},"outputs":[{"name":"stdout","text":"Sample of text files from the dataset directory:\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/Stocks/rlgt.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/Stocks/cht.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/Stocks/klic.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/Stocks/sni.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/Stocks/fcfs.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/Stocks/slgn.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/Stocks/cowz.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/Stocks/muj.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/Stocks/agfsw.us.txt\n/kaggle/input/price-volume-data-for-all-us-stocks-etfs/Stocks/csii.us.txt\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import pandas as pd\n\nprint(\"------------- ETF's Data Format -------------------\")\n\nfile_path = '/kaggle/input/price-volume-data-for-all-us-stocks-etfs/ETFs/slyv.us.txt'\n\ntry:\n    slyv_df = pd.read_csv(file_path, sep='\\t')\n    print(f\"Data from {file_path} loaded successfully. Displaying first 5 rows:\")\n    display(slyv_df.head())\nexcept FileNotFoundError:\n    print(f\"Error: The file {file_path} was not found.\")\nexcept Exception as e:\n    print(f\"An error occurred while loading the file: {e}\")\n\nprint(\"------------- Stocks Data Format -------------------\")\n\nfile_path = '/kaggle/input/price-volume-data-for-all-us-stocks-etfs/Stocks/usrt.us.txt'\n\ntry:\n    slyv_df = pd.read_csv(file_path, sep='\\t')\n    print(f\"Data from {file_path} loaded successfully. Displaying first 5 rows:\")\n    display(slyv_df.head())\nexcept FileNotFoundError:\n    print(f\"Error: The file {file_path} was not found.\")\nexcept Exception as e:\n    print(f\"An error occurred while loading the file: {e}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T16:44:53.747321Z","iopub.execute_input":"2026-01-04T16:44:53.747734Z","iopub.status.idle":"2026-01-04T16:44:53.777514Z","shell.execute_reply.started":"2026-01-04T16:44:53.747707Z","shell.execute_reply":"2026-01-04T16:44:53.776594Z"}},"outputs":[{"name":"stdout","text":"------------- ETF's Data Format -------------------\nData from /kaggle/input/price-volume-data-for-all-us-stocks-etfs/ETFs/slyv.us.txt loaded successfully. Displaying first 5 rows:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"          Date,Open,High,Low,Close,Volume,OpenInt\n0   2005-02-25,44.396,44.875,44.396,44.875,2993,0\n1  2005-02-28,45.051,45.124,44.819,44.851,49043,0\n2   2005-03-01,45.051,45.293,44.972,45.293,2247,0\n3    2005-03-02,45.348,45.348,45.348,45.348,371,0\n4  2005-03-03,45.285,45.314,45.043,45.314,13855,0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date,Open,High,Low,Close,Volume,OpenInt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2005-02-25,44.396,44.875,44.396,44.875,2993,0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2005-02-28,45.051,45.124,44.819,44.851,49043,0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2005-03-01,45.051,45.293,44.972,45.293,2247,0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2005-03-02,45.348,45.348,45.348,45.348,371,0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2005-03-03,45.285,45.314,45.043,45.314,13855,0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"------------- Stocks Data Format -------------------\nData from /kaggle/input/price-volume-data-for-all-us-stocks-etfs/Stocks/usrt.us.txt loaded successfully. Displaying first 5 rows:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"         Date,Open,High,Low,Close,Volume,OpenInt\n0  2007-05-04,38.705,38.757,38.481,38.496,5289,0\n1  2007-05-07,38.566,38.566,38.532,38.532,4257,0\n2  2007-05-08,38.424,38.424,38.278,38.295,6454,0\n3  2007-05-09,38.748,38.748,38.613,38.613,5161,0\n4     2007-05-10,38.566,38.633,38.2,38.2,12897,0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date,Open,High,Low,Close,Volume,OpenInt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2007-05-04,38.705,38.757,38.481,38.496,5289,0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2007-05-07,38.566,38.566,38.532,38.532,4257,0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2007-05-08,38.424,38.424,38.278,38.295,6454,0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2007-05-09,38.748,38.748,38.613,38.613,5161,0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2007-05-10,38.566,38.633,38.2,38.2,12897,0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"print(\"--------- Features List -----------\")\nprint(\"Features List: Date, Open, High, Low, Close, Volume, OpenInt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T16:44:53.778605Z","iopub.execute_input":"2026-01-04T16:44:53.778918Z","iopub.status.idle":"2026-01-04T16:44:53.784567Z","shell.execute_reply.started":"2026-01-04T16:44:53.778884Z","shell.execute_reply":"2026-01-04T16:44:53.783624Z"}},"outputs":[{"name":"stdout","text":"--------- Features List -----------\nFeatures List: Date, Open, High, Low, Close, Volume, OpenInt\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}